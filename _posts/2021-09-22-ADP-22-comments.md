---
layout: post
title:  "데이터분석전문가(ADP) 22회 실기시험 후기"
subtitle:   "데이터분석전문가(ADP) 22회 실기 문제 복기 및 후기"
categories: data
tags: ADP
comments: true
use_math: true
---

> 데이터분석전문가(ADP) 22회 실기 시험 응시 후기입니다. <br> 22회 실기 문제 복기 및 후기 위주로 써보았습니다.

* 수험 정보 : 데이터분석전문가(ADP) 22회 실기 시험
* 고사장 : 한국소프트웨어인재개발원
* 시험 일시 : 2021년 9월 12일(일) 13:00~17:00(240분)
	* 입실시간: 11:50~12:30분, 입실가능시간 엄수
	* 12:30부터 응시생 유의사항 안내 및 PC 환경 점검이 이루어짐
* 준비물 : 신분증, 검정색 볼펜, 개인자료

<
## 1. 고사장 환경
제가 실기 시험을 응시한 장소는 가산디지털역에 있는 한국소프트웨어인재개발원이었습니다.

### 고사장
* 서울 지역은 고사장으로 성동공업고등학교와 한국소프트웨어인재개발원, 이렇게 2곳으로 진행되었습니다.
* 저는 고사장 차이는 크게 없는 것 같아서 집에서 조금더 가까운 한국소프트웨어인재개발원에서 시험을 응시하였습니다.
* 실기 신청일에 성동공고가 더빨리 마감된 것을 보아, 응시자들의 고사장 선호도가 있는 것 같다고 느꼈습니다. 만약 **원하는 고사장이 있으면 신청일 오픈 시간에 바로 신청**하는 것을 추천드립니다.

### PC 환경
* 지난 후기들을 찾아보았을 때 각 고사장마다 모니터 크기나 성능이 차이가 있다고하여 걱정을 많이 했는데 다행히 정상적인 모니터 당첨이 되었습니다.
* 12시 10~20분쯤 고사실에 입실하였는데 반정도 인원이 차있었고, 어떤 분은 미리 모니터와 키보드 확인을 하여 다른 빈자리의 모니터와 키보드로 바꾸고 계셨습니다.
* 간혹 가다가 시험 중에 모니터가 되지 않는 경우도 있다고 하니 **기본적인 PC 환경은 꼭 점검**하는 것을 추천드립니다.

## 2. 시험 진행 환경
이번 시험 역시 지난 회차와 동일하게 **구름(goorm) 사이트에 접속하여 클라우드 환경에서 시험이 진행**되었습니다. <br>시험 시작 전에 접속 및 사용 방법에 대한 설명이 적힌 책자를 제공해주는데, 책자에 적힌대로 진행하면 로그인이나 클라우드 환경에서 분석을 진행하는데 있어 문제가 없을 것이라 생각합니다.
* 시험시간 중 포털 및 검색 화면 등 시험진행에 필요한 화면 적발 시 부정행위 처리 되니 유의해야 합니다.
* 저는 분석책 1권과 준비한 프린트물(링제본) 이렇게 챙겼는데, 다른분들은 책만 여러권 챙겨오신 분도 있으시고 프린트물만 들고오신 분도 있으시니 각자 개인 기호에 맞게 준비를 해오시면 될 것 같습니다.

인터넷 연결이 되어있어서 추가 필요한 패키지 설치가 가능합니다. 하지만 사전에 패키지 설치로 인한 환경 오류는 응시자의 책임이라고 공지를 해주기 때문에, **꼭 필요한 경우가 아니면 추가적인 패키지 설치는 추천드리지 않습니다.**
* 시험일 전 홈페이지에 패키지 목록을 제공하니 사용하시는 패키지가 있는지 확인을 하시는 것이 좋을 것 같습니다.
* 22회 제공 패키지 리스트 : [제22회 데이터분석 전문가(ADP) 실기시험 응시안내](https://www.dataq.or.kr/www/board/view.do?bbsKey=eyJiYnNhdHRyU2VxIjoxLCJiYnNTZXEiOjUxNDUyMH0=&boardKind=notice) 

## 3. 22회 ADP 실기 문제 복기

22회 실기 시험에서는 크게 2가지 문제(기계학습, 통계분석)가 출제되었으며, 기계학습 50점 통계분석 50점으로 구성되었습니다. <br> 카페에 올라온 후기를 바탕으로 제 기억을 덧붙여 정리하였습니다. (저는 R로 시험을 봐서 문제 복기는 R코드 위주로 진행됩니다)
* 출처 : [데이터 전문가 포럼 - NAVER 카페](https://cafe.naver.com/sqlpd/24418)
* 소문제마다 점수가 할당되어 있었는데 이부분은 생각이 나질 않습니다😭
* 답안은 제 개인적인 의견으로 작성되었으며, 이번 시험은 불합격일 것 같아서 그냥 참고만 해주셨으면 좋겠습니다. 복기를 하는데 아쉬움만 남네요ㅠㅠ 다음 시험은 더 잘 볼 수 있도록 준비를 더욱 잘해야겠다는 생각이 듭니다.
<br>
### 1. 기계학습 (50점)
> 특징 : 데이터에 헤더가 없었고, 시험지에 변수명 제공해줌

* 데이터셋 : 피마 인디언 당뇨병 데이터(Pima Indian Diabetes)
	* [Kaggle: Pima Indian Diabetes 데이터 세트](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

#### 1.1 데이터 탐색
#### 1.1.1 탐색적 데이터 분석 수행(시각화 포함)
- `dim()`, `str()`, `summary()` 기본 함수
- 결측치 확인
- 독립변수 전체 히스토그램+박스플랏+pairplot
- 타겟변수 분포 그래프(불균형 확인)
- 변수 전체 상관관계

#### 1.1.2 이상치 처리(이상값 대체방안 제시)
- **아쉬운 부분** : 위의 EDA 문제에서 일부 이상치를 발견하여 이상치 처리를 1.1.1 문제에서 진행하였는데, 1.1.2 문제에서 해결하여 적었어야하지 않았나 생각합니다. (어느 부분에서 감점을 할지 감이 안잡히니 더 걱정됩니다😭)
- 독립변수 summary()와 히스토그램+pairplot을 통해 이상치 식별을 할 수 있었습니다.
	- 일부 단일 독립변수의 분포에서 크게 벗어나는 99999, 9999 등의 값이 1~3개로 존재하는 경우가 있었음
	- 의도적으로 이상치를 변수 범위에서 크게 벗어나도록 넣은듯 하였음
- 의도적으로 변수 범위에 크게 벗어난 이상치(99999, 999 등)의 경우에는 1~3개로 존재하여 제거해주었습니다.
	- 지금 생각해보니 제거보다는 해당 변수 분포에서의 MAX 값으로 처리해주는 것이 더 모범 답안이었을 것 같습니다. EDA 부분에서 해당 과정을 진행했다보니 아무 생각없이 제거를 한 것으로...😭
- 이 외에도 일부 독립변수의 경우 값들이 이상치를 보여서 상하한선 5% 기준으로 이상치 대체를 진행하였습니다.
	- 나이와 임신횟수의 경우 실제적인 정보이기에 이 두변수를 제외하고 이상치 대체를 진행하였습니다.
	- 일반적으로 이상치 대체의 경우 IQR을 적용하지만 데이터에 대한 큰 변환을 줄 수 있다고 판단하여 IQR을 사용하지 않고 상하한 5% 기준으로 이상치 대체를 사용했다고 서술하였습니다.
	- 이상치 대체 전후 summary 값을 첨부하여 비교하였습니다.
#### 1.1.3 앞선 두 단계에서 얻은 향후 분석시 고려사항 작성
- **아쉬운 부분** : 
- 결측치가 없는 것을 확인하였고 이상치 대체를 진행하였다고 언급하였습니다.
-  또한 타겟변수 분포가 불균형(imbalance)하다는 것을 언급하며 이는 분석함에 있어 유의해야할 부분이며, 타겟변수 분포(0,1)별 독립변수에 대한 차이가 있는지 확인해야한다고 하였습니다.
	- (아래에 불균형 관련으로 문제가 나와서) 2:1정도로 차이가 나니 up-sampling 또는 under-sampling을 해야할수도 있다고 하였습니다.
- 그외에는 나름 이것저것 쓴 것 같은데 크게 생각 안나네요. 위를 메인으로 썼던 것 같습니다.
<br>
#### 2.1 클래스 불균형 처리
#### 2.1.1 오버샘플링 과정 설명하고 결과 작성
- caret 패키지의 `upSample()` 함수를 사용하였습니다.
- 업샘플링 : 해당 분류에 속하는 데이터가 적은 쪽을 표본으로 더 많이 추출하는 방법
- 업샘플링 전후의 `dim()`, `summary()` 아웃풋값을 비교하였습니다.
- 
#### 2.2.2 언더샘플링 과정 설명하고 결과 작성
- caret 패키지의 `downSample()` 함수를 사용하였습니다.
- 언더샘플링 : 해당 분류에 속하는 데이터가 많은 쪽을 적게 추출하는 방법
- 언더샘플링 전후의 `dim()`, `summary()` 아웃풋값을 비교하였습니다.

#### 2.2.3 둘 중 선택하고 이유 설명
- 둘 중 선택한다면 언더샘플링을 선택한다고 하였습니다.
- 업샘플링의 경우 데이터가 적은 쪽을 표본으로 더 많이 추출하면서 정보 손실은 없지만 중복 관측치가 생기게 되어 오버 피팅에 대한 가능성이 있습니다. 다운샘플링을 하게 된다면 데이터가 많은 쪽을 적게 추출함으로 정보 손실이 있을 수 있지만, 다운샘플링 전후의 시각화 및 summary 값을 비교하여 큰 차이가 나지 않아 다운샘플링을 진행해도 괜찮을 것 같다고 판단하였습니다. 그렇기 때문에 해당 데이터셋의 경우에는 굳이 중복 관측치를 만들면서까지 업샘플링을 하지않고 언더샘플링을 선택하겠다고 서술하였습니다.
<br>
#### 3.1 모델링
#### 3.1.1 최소 3개 이상 알고리즘 제시하고 정확도 측면의 모델 1개와 속도 측면의 모델 1개를 꼭 구현(총 2개 이상)
- **아쉬운 부분** : 알고리즘보다 모델 위주로 설명을 적어서 이부분에서 감점을 받을 것 같다는 생각이 듭니다😭 만약 적는다면 선형/배깅/부스팅 알고리즘을 제시하여 부가적인 설명을 적을 것 같습니다.
- 3개 알고리즘 : Logistic Regression, Random Forest, XGBoost
- 정확도 측면의 모델 1개 : Random Forest
- 속도 측면의 모델 1개 : Logistic Regression

#### 3.1.2 모델 비교하고 결과 설명
- **아쉬운 부분 1** : 앞의 문제에서 언더샘플링을 해준만큼 해당 부분을 조금 더 언급하거나, 데이터와 독립변수가 추가적으로 더 수집되면 더욱 비교를 잘할 수 있을 것 같다 등과 같이 언급하면 좋지 않았을까 생각합니다.
- **아쉬운 부분 2** : 데이터수가 많지 않은만큼 k-fold cross validation을 사용하여 모델별 mean accuracy를 산출해서 비교하는 것이 더 정확하지 않았을까 생각합니다.
- 속도를 계산할 때는 `Sys.time()` 함수를 사용하였습니다.
	- 해당 함수는 시스템 함수로 코드 청크의 시작과 끝의 시간 차이를 측정해줍니다.
- 정확도 측면에서는 Random Forest, 속도 측면에서는 Logistic Regression이 좋았습니다.
- Confusion Matrix 값을 사용하여 전체적인 평가 지표를 산출 및 제공하였습니다.

####  3.1.3 속도 개선을 위한 차원 축소 설명하고 수행, 예측 성능과 속도 비교하고 결과 작성
- **아쉬운 부분** : 표준화 및 주성분분석을 진행 시 test leakage를 조심해야하는데, 이 부분을 간과하고 진행한듯한 기억이 납니다😭 이 부분은 다시 공부하여 내용 정리하는 글을 올릴 예정입니다.
- 주성분분석(PCA)를 사용하였으며, 해당 개념을 설명하였습니다.
- scaling을 진행하였고, `scale()` 함수를 사용하였습니다.
- 설명 분산 누적은 85%로 설정하였고, 요약된 주성분이 전체 데이터의 85%정도를 설명하였습니다. (Comp4 정도까지)
- 속도와 예측 성능이 둘다 다소 하락한 것을 확인할 수 있었습니다. 만약 데이터와 독립 변수가 추가적으로 더 있다면 PCA로 진행했을 때, 속도가 더욱 하락하고 예측 성능도 어느정도 높게 나올 수 있을 것이라고 서술했습니다.​
<br><br>
### 2. 통계분석 (50점)
> 총 4개의 문제가 있었으며, '산공과 교수님이 냈나?'할 정도로 품질경영 문제가 나와서 당황스러웠습니다🤐
​
#### 1.1 금속 성분 함유량 데이터(변수 1개) - 제품에 금속 재질 함유량의 분산이 1.3을 넘으면 불량이라고 보고 있는데 제조사별로 차이가 난다고 제보를 받았으며, 분산에 대해 검정을 수행하시오. (유의확률 0.05)
- **아쉬운 부분 1** : 아무리 기억을 복기해도 분산을 제공했던 기억은 없는데, 문제를 해석할 때 위와 같이 해석을 해야했던 것 같습니다. 아니면 제가 맘이 급해서 못 봤을수도 있어요😭
- **아쉬운 부분 2** : 일표본 카이검정(One Sample Chi-square Test)을 해야하는건 파악했는데, 어떻게 진행해야하는지 코드를 몰라서 진행하지 못했습니다.
#### 1.1.1 연구가설과 귀무가설 작성
- $H_{0} : \sigma^{2} = \sigma_{0}^{2}$
#### 1.1.2 양측 검정
- **삽질 대잔치** : 등분산성 검정을 해야한다고 판단하여 `var.test()`를 사용할 때 x는 데이터가 들어가는데 y에는 vector가 들어가야하는데 어떻게 해야하는지 버벅거렸습니다. 그냥 1.3 분산 가지는걸로 임의로 만들어서 비교하면 되지 않았을까 생각했는데, 일표본 카이검정이니 이건 아니었겠죠..? 에효😭
	- `var.test(x, y, ratio= 1, alternative=c("two.sided","less","greater"), conf.level=0.95)`
- **정답** : 분산을 추정하고 분산이 사용자 지정 값과 같다는 카이 제곱 검정을 사용하여 귀무 가설 검정 및 분산에 대한 신뢰 구간을 구하는 함수가 있었습니다. EnvStats 패키지의 `varTest` 함수를 사용하는게 제일 베스트였던 것 같습니다.
	- [varTest:  One-Sample Chi-Squared Test on Variance](https://www.rdocumentation.org/packages/EnvStats/versions/2.3.1/topics/varTest)
	- `varTest(x, alternative = "two.sided", conf.level = 0.95, sigma.squared = 1, data.name = NULL)` 에서 sigma.squared = 1.3으로 지정하여 진행하면 됩니다.
#### 1.1.3 검정통계량, 가설 채택
- 검정 통계량 : $\chi_{0}^{2} = \frac{(n-1) S^{2}}{\sigma_{0}^{2}}$

<br>

#### 2.1 Lot별 200개에 대한 불량 제품 수량 데이터(변수 2개 -  lot번호, 불량제품수)
#### 2.1.1 불량률 관리도에 따라 관리중심선(CL : Center Line), 관리 상한선(UCL : Upper Control Limit), 하한선(LCL : Lower Control Limit) 구하기
- 불량률에 대한 관리도이기에, 먼저 불량률을 산출해주었습니다. ($\frac{불량제품수*100}{200}$)
- 관리중심선(CL)은 평균값이고, 관리 상한선(UCL)과 관리 하한선(LCL)은 평균으로부터 $3\sigma$(표준편차) 떨어진 값입니다.
	- 관리 상한선(UCL) : $\mu + 3\sigma$
	- 관리 하한선(LCL) : $\mu - 3\sigma$

#### 2.1.2 관리도 시각화
- 시각화는 구글에 python control chart 검색하면 많이 나오고, 결국 관리도가 생소한 말이지만, 관리 중심선 = 평균, 관리 상한선과 하한선은 평균 기준 3표준편차씩 거리에 위치한 선입니다.**
- 관리도 시각화는 블로그 글에서 잠깐 언급한 적 있는데, 아래의 그림과 비슷하게 CL은 빨간선 실선 & UCL, LCL은 파란색 점선으로 시각화하였다. 
	- 블로그 글 : [제조업에서 데이터 분석이란?](https://ysjang0926.github.io/etc/2020/12/13/manufacturing_data_intro/)
![control chart](https://user-images.githubusercontent.com/54492747/102012127-e106cd80-3d8b-11eb-8e48-cdb9f1ad319f.png)
(사진 출처: [control chart](https://www.qimacros.com/lean-six-sigma-articles/stability-analysis-vs-capability-analysis))

<br>

#### 3.1 데이터 없음 - 표에 제품 1, 2를 만드는데 재료 a, b, c가 일부 사용되며, 제품 1과 2를 만들 때 12만원과 18만원을 벌 수 있다.  재료는 한정적으로 주어지는데, 이때 최대 수익을 낼 수 있을 때의 제품 1과 제품2의 개수를 알고 싶음 (제품 수량을 최대로 뽑으면서 수익이 최적이 되도록)
- 문제 예시는 아래와 같습니다. 여기서 조금 다른 점은 원료가 3개이고, 제품 1의 경우 하나를 생산할 때 **재료 a를 n개 얻고** 재료 b를 n개 쓰고 재료 c를 n개 쓴다는 것입니다.
![ncs문제](https://user-images.githubusercontent.com/54492747/134377609-903a6c64-d38c-42ee-a362-4fbffc51de92.JPG)
(사진 출처: [NCS수리 문제풀이](https://blog.naver.com/vbvb15/221945270576))
- 위의 내용을 방정식으로 바꿔서 풀어내는 문제이며, 연립방정식 문제라고 볼 수 있습니다.
	- 솔직히 전형적인 ncs 문제가 갑자기 왜 나왔는지 이해가 되지 않습니다. 일단 풀라고 해서 풀긴 했는데, 어이없어하면서 for문을 짰던 기억이 납니다.
- 이중 for문을 짰으며 수익값이 최대가 되는 부분과 이때의 제품 1과 제품2의 개수를 print하도록 하였습니다.

<br>

#### 4.1 데이터 없음 - 상품 a와 b가 있을 때 다음과 같은 구매 패턴이 있다고 한다. aa bb aaaa bbbb a b aa bb aa  bbb aa bb a b (정확히 기억 안나지만 대충 비슷함) 구매하는 패턴으로 보아 두 상품이 연관이 있는지 궁금함
- 일단 문제를 보고 욕부터 먼저 했습니다. 비모수 검정인 것 같은데, 데이터 없이 이렇게 주고 검정하라고 할 줄은 몰랐습니다. 어떻게 해야할지 몰라서 손도 못대고 이 문제는 포기하고 넘어갔습니다.
- 다른분들 후기를 보니 **Run Test**를 진행하면 된다고 합니다.
	- Run-test : 일련의 연속적인  관측값들이  임의적(random)으로 나타난 것인지를 검정하는 방법이며, 관측값들이  얻어진 순서에 근거하는 비모수적  검정법
	- 블로그 설명 : [Run-test](https://blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=li0224il&logNo=220722414973)
- **삽질 대잔치** : 
#### 4.1.1 연구가설과 귀무가설 작성
- $H_{0}$ : 연속적인 관측값이 임의적이다. (=표본이 무작위로 추출되었다)
#### 4.1.2 평균과 표준편차
![run-test](https://user-images.githubusercontent.com/54492747/134380617-2e9ed1e2-0a98-405f-bbcf-bf49d9d59364.png)

#### 4.1.3 가설 채택
- tseries 패키지의 `runs.test` 함수를 사용하면 됩니다. (수열은 두가지 수준으로 된 요인어야함)
- 예시코드
![run-test-code](https://user-images.githubusercontent.com/54492747/134381430-fa43f63e-9090-4f0e-9927-93c8835c10dd.JPG)

<br> 

## 4. 전반적인 시험 후기
- 문제가 명확하지 않음
	- ADP 시험 문제 및 답안 제출이 수험자가 어떠한 결정을 내려서 어떠한 아웃풋을 냈는지 채점자에게 서술하는 식으로 진행되지만, 문제가 참 애매하다고 생각되었습니다. 코에 걸면 코걸이, 목에 걸면 목걸이 느낌이랄까😤
- 점수 공개 시 채점 기준 불명확한 점이 어이없음
	- 제가 저만의 판단 하에 답안을 서술하였고 최종 점수가 공개되었을 때, 어느 부분에서 감점을 당했고 채점자가 원하는 부분이 어떤 부분이었는지 전혀 알 수 없다는 점입니다.
	- 그래도 명색이 시험인데 이러하다의 기준이 있어야하는데, 수험자의 경우 그 점수를 받아들이기만 하는 것이다보니 답답함이 생길 수 밖에 없을 것 같습니다.
- 23회차를 준비해야겠다는 생각
	- 기계학습 부분은 통계분석 부분에 비하여 무난했지만, 통계분석의 경우 생각보다 많이 못 풀었다고 생각하기에 23회차를 준비하는 것이 확실해졌습니다. (복기를 해보니 기계학습 부분도 생각보다 더 형편없이 답안을 서술한 것 같아서 아쉬움만 남네요😭)
	- 기계학습 부분은 '앞으로 어떻게 준비해야겠다'의 계획이 세워졌는데, 통계분석의 경우 앞으로 어떻게 준비를 해야할지 감이 잡히지 않아 고민입니다. 아직 분석하기에 공부할 것도 많고 부족함이 많다고 깨달은 회차입니다.

기계학습과 통계분석 모두 간단하게 제가 썼던 답안을 적어보았는데, 무조건적인 답이 아니니 만약 서술한 내용 중 틀린 부분이 있다면 언제든지 지적해주시면 감사하겠습니다.🤗
<br>
흑흑 이 글을 읽으시는 모두 12월 시험 화이팅입니다!
