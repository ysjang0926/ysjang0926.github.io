---
layout: post
title:  "넷플릭스 - 개인화 추천을 위한 파운데이션 모델"
subtitle:   "Let's not be a fool"
categories: etc
tags: etc_til
comments: true
---

- Netflix의 추천 시스템 아키텍처를 통합하고 확장 가능한 방식으로 재설계한 내용을 다룹니다✍🏻
- 내용 그대로 이해하고 싶으시면, 원본 콘텐츠([Foundation Model for Personalized Recommendation](https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39))를 읽어보시길 권장 드립니다. 원문을 통해 더욱 깊이 있는 정보를 얻으실 수 있을 거에요😉

---------

# 🎯 동기 및 배경
Netflix의 개인화 추천 시스템은 매우 복잡한 시스템입니다. "Continue Watching"이나 "Today’s Top Picks for You" 같은 각각의 니즈를 충족시키는 다양한 특화된 머신러닝 모델들을 갖추고 있습니다. <br>
하지만, 비즈니스 니즈가 늘어남에 따라 개인화 알고리즘 세트를 확장하면서 추천 시스템 유지보수 비용이 상당히 증가했습니다. 게다가, 대부분의 모델이 공통 데이터를 사용하긴 하지만 독립적으로 학습되기 때문에, 한 모델에서 이루어진 혁신을 다른 모델로 이전하기가 어렵다는 문제가 있습니다. 이런 상황은, 회원 선호 학습을 중앙 집중화하고 다양한 모델 전반에서 접근성과 활용도를 높일 수 있는 새로운 추천 시스템 아키텍처의 필요성을 강조하게 만들었습니다. <br>

특히, 이러한 모델들은 대부분 Netflix 플랫폼 내에서 사용자의 최근 상호작용 이력으로부터 특성(features)을 추출합니다. 하지만 대부분의 경우, 서비스 지연(latency)이나 학습 비용의 제약으로 인해 아주 짧은 기간의 이력에만 한정되는 경향이 있었습니다. <br>
이런 한계는, 유저의 포괄적인 상호작용 이력과 Netflix의 콘텐츠에 대한 정보를 매우 대규모로 통합하는 파운데이션 모델을 개발하도록 영감을 주었습니다. 이 모델은 다른 모델들에게 이러한 학습 결과를 공유 모델 가중치(for fine tuning) 또는 임베딩을 통해 직접적으로 전달할 수 있도록 설계되었습니다. <br>

이러한 파운데이션 추천 모델 구축의 추진력은 자연어 처리(NLP) 분야에서 대형 언어 모델(LLM)로의 패러다임 전환에서 착안한 것입니다. NLP 분야에서는 수많은 소규모 특화 모델들 대신, 단일 대형 언어 모델이 다양한 작업을 직접 수행하거나 최소한의 파인튜닝으로 처리하는 방향으로 이동하고 있습니다. <br>

이 변화로부터 얻은 핵심 인사이트는 다음과 같습니다.
- **데이터 중심 접근(Data-Centric Approach)**: 피처 엔지니어링에 크게 의존하는 모델 중심 전략에서 벗어나, 고품질 대규모 데이터를 축적하고 가능한 한 엔드투엔드 학습을 목표로 하는 접근입니다.
- **반지도 학습(Semi-Supervised Learning) 활용**: LLM에서의 next-token prediction objective는 매우 효과적임이 입증되었습니다. 이를 통해 라벨이 없는 대규모 데이터를 활용한 반지도 학습이 가능하며, 동시에 모델이 세계 지식(world knowledge)에 대한 깊은 이해를 갖추도록 도와줍니다.

이러한 인사이트들은 파운데이션 모델 설계에 반영되었으며, 수많은 소규모 특화 모델 유지에서 벗어나 확장 가능하고 효율적인 시스템 구축을 가능하게 했습니다. <br>
**반지도 학습 데이터와 모델 파라미터를 대규모로 확장**함으로써, 현재의 니즈를 충족할 뿐만 아니라 앞으로 변화하는 요구사항에 동적으로 적응할 수 있는 모델을 개발하고, 지속 가능한 혁신과 자원 효율성을 보장하는 것을 목표로 하고 있습니다.

<br> <br>

# 📊 데이터 처리 방식
Netflix에서 사용자들의 참여도(engagement)는 매우 넓은 스펙트럼을 가집니다. 단순히 브라우징하는 사용자부터 영화를 끝까지 시청하는 사용자까지 다양합니다. <br>
2024년 말 기준, Netflix는 3억 명 이상의 사용자를 보유하고 있으며, 이는 수천억 건에 달하는 상호작용으로 이어집니다. 이 규모는 대형 언어 모델(LLM)에서 다루는 토큰 수와 비교할 만한 수준입니다.  <br>

그러나 LLM과 마찬가지로 데이터의 양보다 **품질**이 더 중요합니다. 이러한 데이터를 효과적으로 활용하기 위해 우리는 **상호작용을 토큰화(tokenization)하는 과정**을 통해 의미 있는 이벤트를 식별하고 중복을 최소화합니다. <br>

### 사용자 상호작용 토큰화(Tokenizing User Interactions)
모든 사용자 행동이 선호도를 이해하는 데 동일하게 기여하는 것은 아닙니다. 토큰화는 **시퀀스 내에서 의미 있는 "토큰"이 무엇인지 정의**하는 데 도움이 됩니다. <br>

NLP의 Byte Pair Encoding(BPE) 방식과 유사하게, 인접한 행동들을 병합하여 새로운 고차원의 토큰을 만들어냅니다. 그러나 언어 토큰화와 달리 이러한 새로운 토큰을 생성할 때 어떤 정보를 보존할지 신중히 고려해야 합니다. <br>
예를 들어, 총 시청 시간을 합산하거나 참여 유형을 집계하는 방식으로 중요한 정보를 유지할 수 있습니다. <br>

아래 그림은 사용자 상호작용 히스토리를 중요한 정보를 유지하며 동일 타이틀에 대한 행동을 병합하여 토큰화하는 예시입니다. 

![image](https://github.com/user-attachments/assets/b816f32c-6e81-460c-ab51-8af3a1fc01a5)

이렇게 세밀한 데이터와 시퀀스 압축 간의 trade-off은 LLM에서의 vocabulary size(어휘 크기)와 context window(문맥 길이) 간의 균형과 유사합니다. <br>
Netflix의 경우, 목표는 **상호작용 히스토리의 길이와 각 토큰에 보존되는 세부정보 수준 사이의 균형을 맞추는 것**입니다. 너무 손실(lossy)이 많은 토큰화는 중요한 시그널을 잃게 만들 수 있고, 반대로 지나치게 세밀한 시퀀스는 처리 시간과 메모리 측면에서 실용적인 한계를 넘을 수 있습니다. <br>

이러한 전략들을 사용하더라도, 액티브한 사용자들의 상호작용 히스토리는 수천 건에 이를 수 있으며, 이는 표준 self-attention 레이어를 사용하는 transformer 모델의 처리 용량을 초과합니다. 추천 시스템에서는 추론 시 context window가 보통 수백 개의 이벤트로 제한됩니다. 이는 모델의 한계 때문이 아니라, 대부분 서비스 지연(latency)이 밀리세컨드 수준으로 요구되기 때문입니다. 이는 보통 LLM 애플리케이션보다 훨씬 더 엄격한 제약입니다. (LLM은 초단위 추론 시간도 허용 가능)

이를 해결하기 위해 학습 단계에서는 두 가지 핵심 솔루션을 사용합니다.
- **Sparse Attention Mechanisms(희소 어텐션 메커니즘)**: low-rank compression(저랭크 압축) 같은 희소 어텐션 기법을 활용해 context window를 수백 개 이벤트까지 확장하면서 계산 효율성을 유지합니다. 이를 통해 더 긴 상호작용 히스토리를 처리하며 장기 선호도를 더 잘 파악할 수 있습니다.
- **Sliding Window Sampling(슬라이딩 윈도우 샘플링)**: 학습 시 전체 시퀀스에서 겹치는 윈도우들을 샘플링하여, 여러 epoch에 걸쳐 사용자의 전체 히스토리의 다양한 부분을 모델이 학습할 수 있도록 합니다. 너무 큰 context window를 요구하지 않으면서도 전체 시퀀스 학습 효과를 확보할 수 있습니다.

추론 단계에서 multi-step decoding이 필요한 경우, KV caching(키-값 캐싱)을 활용해 과거 계산 결과를 효율적으로 재활용하면서 낮은 지연 시간을 유지합니다. <br>

이러한 접근 방식들을 통해, 장기적이고 세밀한 상호작용 모델링에 대한 니즈와 모델 학습/추론의 실용적 제약 간의 균형을 맞출 수 있게 되었습니다. 이를 통해 추천 시스템의 정밀도와 확장성을 모두 개선할 수 있었습니다. <br>

### 각 '토큰' 내 정보 설계(Information in Each 'Token')
사용자 상호작용 시퀀스를 구조화하는 첫 단계가 끝나면, 다음으로 중요한 것은 **각 토큰에 포함되는 정보 자체를 어떻게 정의**할 것인지입니다. LLM들은 일반적으로 단일 임베딩 공간에 input token을 표현합니다. <br>
하지만 사용자 상호작용 이벤트는 이질적인 디테일로 가득합니다.
- 행동 자체의 속성 (지역, 시간, 길이, 기기 종류 등)
- 콘텐츠 정보 (아이템 ID, 장르, 출시 국가 등 메타데이터)

이러한 특성들 중 대부분은 카테고리 변수로 모델 내에 직접 임베딩됩니다. 이는 엔드투엔드 학습 접근 방식에 부합합니다. <br>
하지만 몇몇 특성들은 특별한 처리가 필요합니다. 예를 들어 타임스탬프(time stamp)는 절대 시간 개념과 상대 시간 개념 모두를 반영할 수 있도록 별도의 처리 단계가 필요합니다. 특히 절대 시간은 시간에 민감한 행동을 이해하는 데 매우 중요합니다. <br>

시퀀스 기반 추천 시스템에서 예측 정확도를 높이기 위해, 토큰 특성은 두 가지 범주로 나뉩니다.
- **Request-Time Features(요청 시점 특성)**: 예측 시점에 이용 가능한 특성들 (로그인 시간, 디바이스, 위치 등)
- **Post-Action Features(행동 후 특성)**: 행동 이후에만 알 수 있는 정보들 (어떤 콘텐츠와 상호작용했는지, 시청 시간 등)

다음 상호작용을 예측할 때, 우리는 현재 스텝의 요청 시점 특성과 직전 스텝의 행동 후 특성을 결합합니다. 이를 통해 각 토큰은 직전 행동 패턴과 현재 상황 정보를 모두 포괄할 수 있게 됩니다.

<br><br>

# 🏗️ 모델 목표 및 구조
앞서 언급했듯이, 기본 접근 방식은 GPT와 유사한 autoregressive 방식의 next-token prediction objective를 사용합니다. 이 전략은 라벨링되지 않은 대규모 사용자 상호작용 데이터를 효과적으로 활용할 수 있게 해줍니다. 이러한 objective는 추천 시스템에서도 이미 여러 성공 사례들이 존재합니다. <br>

하지만, 언어 작업(language tasks)과 추천 작업(recommendation tasks) 간의 뚜렷한 차이점을 고려하여, objective에 몇 가지 중요한 수정사항을 적용했습니다.<br>

#### 서로 다른 상호작용에 다른 가중치 부여 (예: 전체 영화 시청 vs 예고편 시청)
일반적인 GPT 같은 LLM들의 pretraining phase(사전학습 단계)에서는 모든 target token(목표 토큰)이 동일한 가중치를 가지고 학습됩니다. <br>
반면, Netflix 모델에서는 모든 사용자 상호작용이 동일하게 중요한 것은 아닙니다. 예를 들어, 5분짜리 트레일러 재생과 2시간짜리 영화 전체 시청이 동일한 중요도로 다뤄지는 것은 바람직하지 않습니다.

#### 장기 종속성 파악을 위한 다중-토큰 예측 사용
더 큰 도전 과제는 long-term user satisfaction을 특정 상호작용 또는 추천 결과와 정렬(alignment)시키는 것입니다. <br>
이를 해결하기 위해 학습 중 single token 대신 next n tokens을 예측하는 multi-token prediction objective를 도입할 수 있습니다. 이렇게 하면 모델이 장기적 의존성(long-term dependencies)을 더 잘 학습하고, 지나치게 근시안적인(myopic) 예측을 피할 수 있게 됩니다.

#### 아이템 ID 예측과 함께 보조 예측 목표(장르 등) 활용
input data 내 여러 필드를 auxiliary prediction objectives로 활용할 수 있습니다. <br>

예를 들어, 원래 시퀀스 내 아이템들로부터 장르 정보를 추출하고 이를 보조 타겟으로 사용하는 방식입니다. 이러한 접근은 여러 가지 장점이 있습니다.
- noisy한 아이템 ID 예측에 대한 regularizer(규제자) 역할
- 사용자 의도나 장기적 장르 선호에 대한 추가적 통찰 제공
- 계층적 구조(hierarchical structure)를 활용하여 타겟 아이템 ID 예측 정확도 향상

보조 타겟(예: 장르, 원어 등)을 먼저 예측하게 하면, 모델이 후보군(candidate list)을 좁히는 데 도움이 되고 이후 아이템 ID 예측이 더 쉬워집니다.

<br><br>

# 🧩 고유한 도전 과제
추천 시스템 파운데이션 모델을 구축하면서, LLM에서 공통적으로 나타나는 '대규모 사용자 상호작용 데이터로 큰 모델을 학습할 때 발생하는 인프라 문제' 외에도, 추천 도메인 특유의 몇 가지 고유한 도전 과제가 존재합니다. 그 중 가장 대표적인 것은 '**엔티티 콜드스타트(Entity Cold-Starting)'** 문제입니다. <br>

Netflix는 "세상의 모든 사람을 즐겁게 한다"는 미션을 가지고 있으며, 새로운 타이틀이 자주 카탈로그에 추가됩니다. 따라서 추천 파운데이션 모델은 콜드스타트 역량, 즉 아직 아무도 상호작용하지 않은 신규 타이틀에 대해서도 회원들의 선호도를 예측할 수 있어야 합니다. <br>

이를 가능하게 하기 위해, 파운데이션 모델 학습 프레임워크에 다음 두 가지를 포함시켰습니다.
- Incremental Training(점진적 학습)
- Unseen Entity Inference(보지 못한 엔티티에 대한 추론)

### Incremental Training
**✅ 이전 모델 파라미터로 새 모델 워밍업하는 점진적 학습** <br>
파운데이션 모델은 모든 회원의 시청 및 행동 히스토리를 포함하는 방대한 데이터셋으로 학습되기 때문에, 자주 재학습(retraining)하는 것은 비현실적입니다. <br>
하지만 Netflix의 카탈로그와 회원 선호는 계속 변화합니다. LLM은 상대적으로 안정적인 토큰 vocabulary를 사용하기 때문에 점진적 학습이 용이하지만, 추천 모델은 새로운 타이틀이 등장할 때마다 새로운 임베딩이 필요합니다. 따라서 embedding layer와 output component가 지속적으로 확장되어야 합니다. <br>

이를 해결하기 위해 우리는 **warm-start 기법**을 사용합니다. 기존 모델의 파라미터를 재사용하면서, 새로운 타이틀을 위한 파라미터만 새롭게 초기화합니다. <br>

예를 들어, 신규 타이틀의 임베딩은 기존 타이틀 임베딩 평균에 약간의 랜덤 노이즈를 추가하거나, 메타데이터 기반으로 유사 타이틀들의 임베딩 가중 평균을 사용해 초기화할 수 있습니다. 이렇게 하면 새로운 타이틀이 관련성 높은 임베딩으로 시작할 수 있어 파인튜닝 속도가 빨라집니다. 실제로는, 회원 상호작용 데이터가 충분히 쌓이면 초기화 방식 자체는 큰 영향을 미치지 않게 됩니다. <br>

### Dealing with Unseen Entities
**✅ 학습 가능한 ID 임베딩과 메타데이터 기반 임베딩 결합** <br>
점진적 학습을 하더라도 신규 타이틀(launch 이후 추가되는 엔티티) 학습이 항상 빠르게 이루어질 것이라는 보장은 없습니다. 특히, 파운데이션 모델을 자주 파인튜닝하더라도 학습 데이터에 포함되지 않은 새로운 엔티티가 등장하는 경우가 존재할 수 있습니다. <br>

따라서, 추천 파운데이션 모델은 회원 상호작용 데이터뿐 아니라, 엔티티와 입력(input)의 메타데이터 정보 또한 적극 활용할 수 있어야 합니다. 이때 learnable item ID embedding과 metadata embedding을 결합하여 최종 임베딩을 구성합니다. <br>

아래 그림을 통해 각 타이틀은 장르, 스토리라인, 톤 등 다양한 메타데이터와 연결되는 것을 확인할 수 있습니다. 각각의 메타데이터 타입은 해당 임베딩들의 평균으로 표현될 수 있고, 이를 연결(concatenation)하여 타이틀의 메타데이터 기반 임베딩을 구성합니다.

![image](https://github.com/user-attachments/assets/75de6c6a-d216-44c5-a53b-ad793014ba57)

**✅ 콘텐츠 "나이"에 따른 어텐션 메커니즘으로 균형 조정** <br>
최종 타이틀 임베딩은 이 메타데이터 기반 임베딩과 학습 가능한 ID 기반 임베딩을 mixing layer를 통해 결합하여 만듭니다. 단순 합산이 아니라, 엔티티의 'age(출시 경과 시간)'를 기반으로 하는 attention mechanism을 사용합니다. <br>
이렇게 하면, 상호작용 데이터가 적은 신규 타이틀은 메타데이터 기반 임베딩에 더 많이 의존하고, 충분한 데이터가 쌓인 타이틀은 ID 기반 임베딩에 더 많이 의존하게 됩니다. 비슷한 메타데이터를 가진 타이틀이라고 하더라도 사용자 참여도는 다를 수 있기 때문에, 임베딩이 그 차이를 반영해야 합니다. <br>

또한, 학습 과정에서 약간의 랜덤성을 도입하여 모델이 ID 임베딩에만 의존하지 않고 메타데이터에서도 학습하도록 유도합니다. 이러한 방식 덕분에, 출시 직후이거나 아직 사용자 상호작용 데이터가 전혀 없는 타이틀도 reasonable한(합리적인) 임베딩을 가질 수 있게 됩니다. <br>

<br><br>

# 🛠️ 다운스트림 응용 및 활용
추천 파운데이션 모델은 장기적인 회원 선호도를 이해하도록 설계되었으며, 다양한 다운스트림 애플리케이션에서 다음과 같이 활용될 수 있습니다.

#### Direct Use as a Predictive Model (직접 예측 모델로 사용)
**✅ 여러 예측 헤드를 가진 예측 모델로 직접 사용** <br>
이 모델은 기본적으로 사용자가 다음에 어떤 엔티티(아이템)와 상호작용할지 예측하도록 학습되었습니다. <br>
다양한 작업을 처리할 수 있는 여러 개의 predictor heaㅇ를 포함하고 있으며, 예를 들어 특정 장르에 대한 회원 선호도를 예측하는 등의 작업이 가능합니다. 이러한 predictor head들은 다양한 비즈니스 니즈를 직접 충족시키는 데 사용될 수 있습니다. <br>

#### Utilizing Embeddings (임베딩 활용)
**✅ 구성원 및 엔티티(비디오, 게임, 장르)에 대한 임베딩 활용** <br>
모델은 회원, 비디오, 게임, 장르 등과 같은 엔티티들에 대한 가치 있는 임베딩을 생성합니다. <br>
이 임베딩들은 배치 작업(batch job)을 통해 사전 계산되어 저장되고, 오프라인 및 온라인 애플리케이션 모두에서 사용됩니다. 예를 들어, 후보 아이템 추천(candidate generation) 작업에서 유용하게 쓰일 수 있으며, 특정 회원에게 매력적일 수 있는 타이틀을 검색하는 데 사용됩니다. <br>

**✅ 다른 모델 학습과 후보 생성에 임베딩 활용** <br>
타이틀 간 추천(title-to-title recommendation)을 지원하는 고품질 타이틀 임베딩도 제공합니다. 다만, 임베딩 공간(embedding space)은 임의적이고 해석 불가능한 차원들을 가지며, 다른 모델 학습 실행(run)들 간에는 호환되지 않는다는 점이 중요한 고려사항입니다. 이런 이유로 다운스트림 사용자들은 각 모델 재학습 및 재배포 시 임베딩 구조에 대한 가정을 무효화(invalidate)하면서 버그가 발생할 위험을 안게 됩니다. <br>

**✅ 모델 버전 간 임베딩 공간 안정화를 위한 직교 저차원 변환 적용** <br>
이를 해결하기 위해 우리는 임베딩 공간의 안정성을 확보하기 위해 orthogonal low-rank transformation(직교 저차원 변환)을 적용합니다. 이 방식은 파운데이션 모델이 재학습 및 재배포되더라도 user/item embedding space의 각 차원의 의미를 일관되게 유지할 수 있게 해줍니다. <br>

#### Fine-Tuning with Specific Data (특정 데이터로 파인튜닝)
**✅ 특정 애플리케이션을 위한 미세 조정 가능** <br>
모델의 적응력(adaptability)을 활용하여, 각 애플리케이션 특성에 맞춘 데이터로 파인튜닝할 수 있습니다. <br>

사용자는 파운데이션 모델 전체 또는 서브그래프(subgraph)를 자신의 모델에 통합하고, 비교적 적은 데이터와 계산 자원만으로 파인튜닝할 수 있습니다. 이러한 접근 방식은 파운데이션 모델 초기 학습 시 엄청난 자원이 들더라도, 이후 파인튜닝을 통해 기존 특화 모델들과 유사한 성능을 달성할 수 있게 해줍니다.

<br><br>

# 📈 확장성 
Netflix 추천을 위한 파운데이션 모델을 확장하는 과정에서, 대형 언어 모델(LLM)의 성공에서 많은 영감을 얻었습니다. LLM들이 스케일링을 통해 성능이 개선되는 것을 보여준 것처럼, 생성 기반 추천(generative recommendation) 작업에서도 **스케일링**이 매우 중요하다는 사실을 확인했습니다. <br>

성공적인 스케일링을 위해서는 다음이 필수적입니다.
- 강력한 평가 체계(robust evaluation)
- 효율적인 학습 알고리즘(efficient training algorithms)
- 충분한 컴퓨팅 자원(substantial computing resources)

평가 체계는 모델 성능을 효과적으로 구별하고 개선 지점을 식별할 수 있어야 합니다. 스케일링은 **데이터, 모델, 컨텍스트 세 가지 측면**에서 이루어집니다. 여기에는 사용자 상호작용 데이터, 외부 리뷰, 멀티미디어 자산, 고품질 임베딩 등이 포함됩니다. <br>

실험 결과, 스케일링 법칙(scaling law)은 추천 파운데이션 모델에서도 적용 가능함이 확인되었습니다. 데이터와 모델 크기를 증가시킬수록 일관되게 성능이 향상되는 것을 확인할 수 있었습니다.<br>

![image](https://github.com/user-attachments/assets/9df85d68-1ab2-4966-b147-397fa0a35887)

위 그래프는 모델 파라미터 크기와 상대적 성능 향상 간의 관계를 보여줍니다. 추천 모델링에서의 스케일링 법칙(scaling law)을 보여주며, 모델 크기가 커질수록 성능이 증가하는 추세를 나타냅니다. x축은 다양한 규모 차원에서 성장을 강조하기 위해 로그 스케일로 표현되었습니다.

<br><br>

# 🥸 결론
결론적으로, Netflix의 개인화 추천을 위한 파운데이션 모델은 대규모 데이터를 활용하여 회원들에게 더 높은 품질의 추천을 제공하는 통합적이고 데이터 중심적인 시스템 구축의 중요한 진전을 의미합니다. <br>

이 접근 방식은 LLM에서 얻은 인사이트, 특히 semi-supervised learning과 end-to-end training의 원칙을 차용하여, 라벨링되지 않은 방대한 사용자 상호작용 데이터를 활용하는 것을 목표로 합니다. <br>
cold start, presentation bias 등 추천 도메인 고유의 도전 과제를 해결하면서도, 언어 작업과 추천 작업 간의 본질적인 차이를 인정하고 고려합니다. <br>

파운데이션 모델은 예측 모델로 직접 사용되거나, 사용자 및 엔티티 임베딩을 생성하여 다른 애플리케이션에 활용하거나, 특정 목적에 맞게 파인튜닝되는 등 다양한 다운스트림 활용을 지원합니다. 
다양한 특화 모델들로 구성된 기존 방식에서 보다 포괄적이고 일관된 시스템으로의 전환은 개인화 추천 시스템 분야에서 매우 흥미로운 발전을 의미합니다.



이 파운데이션 모델은 넷플릭스가 여러 특수 모델에서 통합된 데이터 중심 시스템으로 전환하는 중요한 단계를 나타내며, 사용자에게 더 나은 개인화된 추천을 제공하는 것을 목표로 합니다. 🎬✨
